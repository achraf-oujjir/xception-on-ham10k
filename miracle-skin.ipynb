{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":332046,"sourceType":"datasetVersion","datasetId":141236}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf \nphysical_devices = tf.config.list_physical_devices(\"GPU\")\ntf.config.experimental.set_memory_growth(physical_devices[0], True)\nimport random, numpy as np, os\n#import tensorflow_datasets as tfds\n#tfds.disable_progress_bar()\n#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n#tf.config.run_functions_eagerly(True)\ndef config_gpu(mp=False):\n    print('Eager Model : ', tf.executing_eagerly())\n    print('TensorFlow Cuda Built Test : ', tf.test.is_built_with_cuda)\n    print('TensorFlow GPU Detected : ', tf.test.gpu_device_name())\n    print('TensorFlow System Cuda Version : ', tf.sysconfig.get_build_info()[\"cuda_version\"])\n    print('TensorFlow System CudNN Version : ', tf.sysconfig.get_build_info()[\"cudnn_version\"] )\n\n    AUTO = tf.data.AUTOTUNE\n    GPUS = tf.config.list_physical_devices('GPU')\n    if GPUS:\n        try:\n            for GPU in GPUS:\n                tf.config.experimental.set_memory_growth(GPU, True)\n                logical_gpus = tf.config.list_logical_devices('GPU')\n                print(len(GPUS), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\") \n        except RuntimeError as  RE:\n            print(RE)\n    if mp:\n        tf.keras.mixed_precision.set_global_policy('mixed_float16')\n        print('Mixed precision enabled')\n        \n#tf.keras.utils.set_random_seed(100)\nconfig_gpu(mp=False)","metadata":{"id":"4NJWk89igA18","outputId":"82063a05-56e3-4b3c-c208-0a99333d3bd7","execution":{"iopub.status.busy":"2024-01-14T17:30:27.510759Z","iopub.execute_input":"2024-01-14T17:30:27.511719Z","iopub.status.idle":"2024-01-14T17:30:41.325758Z","shell.execute_reply.started":"2024-01-14T17:30:27.511685Z","shell.execute_reply":"2024-01-14T17:30:41.324656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <a id='intro'>Plan</a>\n#### [Wavelet with residual block](#the_destination)\n#### [Efficient-net](#Efficient_net)\n#### [Ensemblelearning](#Ensemble_learning)\n#### [Metrics with Graph](#graph)\n#### [Grad-CAM](#Gradcam)\n#### [Result Metrics](#metrics)","metadata":{}},{"cell_type":"markdown","source":"# <a id=''>TF Dataset and Preprocess</a>","metadata":{"id":"EZRwvDtJ0uTn"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport tensorflow as tf\nimport cv2\nfrom keras import backend as K\nfrom keras.layers import Layer,InputSpec\nimport keras.layers as kl\nfrom glob import glob\nfrom sklearn.metrics import roc_curve, auc\nfrom keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential\nfrom sklearn.metrics import roc_auc_score\nfrom tensorflow.keras import callbacks \nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\nfrom  matplotlib import pyplot as plt\nfrom tensorflow.keras import Model\nfrom keras.layers import Lambda\nfrom tensorflow.keras.layers import concatenate,Dense, Conv2D, MaxPooling2D, Flatten,Input,Activation,add,AveragePooling2D,BatchNormalization,Dropout\n%matplotlib inline\nimport shutil\nfrom sklearn.metrics import  precision_score, recall_score, accuracy_score,classification_report ,confusion_matrix\nfrom tensorflow.python.platform import build_info as tf_build_info\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import ImageFile","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:30:41.327381Z","iopub.execute_input":"2024-01-14T17:30:41.327937Z","iopub.status.idle":"2024-01-14T17:30:42.016471Z","shell.execute_reply.started":"2024-01-14T17:30:41.327908Z","shell.execute_reply":"2024-01-14T17:30:42.015161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, cv2\nimport random, math\nimport numpy as np \nimport pandas as pd\nfrom PIL import Image\nimport matplotlib\nmatplotlib.use(\"Agg\")\nimport matplotlib.pyplot as plt\n\nimport tensorflow, keras\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import backend as K\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:30:42.017736Z","iopub.execute_input":"2024-01-14T17:30:42.018053Z","iopub.status.idle":"2024-01-14T17:30:42.031923Z","shell.execute_reply.started":"2024-01-14T17:30:42.018026Z","shell.execute_reply":"2024-01-14T17:30:42.030834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metadata_df = pd.read_csv('D:\\Doctorat\\HAM10000/HAM10000_metadata.csv')\n# metadata_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:30:42.035087Z","iopub.execute_input":"2024-01-14T17:30:42.035801Z","iopub.status.idle":"2024-01-14T17:30:42.044561Z","shell.execute_reply.started":"2024-01-14T17:30:42.035762Z","shell.execute_reply":"2024-01-14T17:30:42.043518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = '/kaggle/input/basedir/base_dir/train_dir'\ntest_path = '/kaggle/input/basedir/base_dir/val_dir'\nbatch_size = 16\n\ntrain_batch_size = 4\nval_batch_size = 4\nimage_size = 224\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:30:42.045895Z","iopub.execute_input":"2024-01-14T17:30:42.046251Z","iopub.status.idle":"2024-01-14T17:30:42.054878Z","shell.execute_reply.started":"2024-01-14T17:30:42.046202Z","shell.execute_reply":"2024-01-14T17:30:42.053919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_augmentation(np_tensor):\n\n  def random_contrast(np_tensor):\n    return np.array(tf.image.random_contrast(np_tensor, 0.5, 2))\n\n  def random_saturation(np_tensor):\n    return np.array(tf.image.random_saturation(np_tensor, 0.2, 3))\n\n  def random_crop(np_tensor):\n    #cropped height between 70% to 130% of an original height\n    new_height = int(np.random.uniform(0.7, 1.30) * np_tensor.shape[0])\n    #cropped width between 70% to 130% of an original width\n    new_width = int(np.random.uniform(0.7, 1.30) * np_tensor.shape[1])\n    # resize to new height and width\n    cropped = tf.image.resize_with_crop_or_pad(np_tensor, new_height, new_width)\n    return np.array(tf.image.resize(cropped, np_tensor.shape[:2]))\n\n  def gaussian_noise(np_tensor):\n    mean = 0\n    # variance: randomly between 1 to 25\n    var = np.random.randint(1, 26)\n    # sigma is square root of the variance value\n    noise = np.random.normal(mean,var**0.5,np_tensor.shape)\n    return np.clip(np_tensor + noise, 0, 255).astype('int')\n\n  def cutout(np_tensor):\n    cutout_height = int(np.random.uniform(0.1, 0.2) * np_tensor.shape[0])\n    cutout_width = int(np.random.uniform(0.1, 0.2) * np_tensor.shape[1])\n    cutout_height_point = np.random.randint(np_tensor.shape[0]-cutout_height)\n    cutout_width_point = np.random.randint(np_tensor.shape[1]-cutout_width)\n    np_tensor[cutout_height_point:cutout_height_point+cutout_height, cutout_width_point:cutout_width_point+cutout_width, :] = 127\n    return np_tensor\n\n  if (np.random.uniform() < 0.1):\n    np_tensor = random_contrast(np_tensor)\n  if (np.random.uniform() < 0.1):\n    np_tensor = random_saturation(np_tensor)\n  if (np.random.uniform() < 0.2):\n    np_tensor = random_crop(np_tensor)\n  if (np.random.uniform() < 0.2):\n    np_tensor = gaussian_noise(np_tensor)\n  if (np.random.uniform() < 0.3):\n    np_tensor = cutout(np_tensor)\n  return np.array(np_tensor)","metadata":{"id":"ONyk8r6T0w1D","outputId":"639d94da-da89-4b28-e40d-0991adebd906","execution":{"iopub.status.busy":"2024-01-14T17:30:42.056425Z","iopub.execute_input":"2024-01-14T17:30:42.056683Z","iopub.status.idle":"2024-01-14T17:30:42.071842Z","shell.execute_reply.started":"2024-01-14T17:30:42.056660Z","shell.execute_reply":"2024-01-14T17:30:42.070672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndatagen = ImageDataGenerator(#preprocessing_function=custom_augmentation,\n                            rescale=1./255,\n                             preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n                            horizontal_flip = True,\n                            vertical_flip=True\n)\ndatagen1 = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n                             rescale=1./255,)\n                             #horizontal_flip = True,\n                             #vertical_flip=True,)\n\n\ntrain_batches = datagen.flow_from_directory(train_path,\n                                            target_size=(image_size,image_size),\n                                            batch_size=train_batch_size,)\n                                           #subset='training')\n\nvalid_batches = datagen.flow_from_directory(test_path,\n                                            target_size=(image_size,image_size),\n                                            batch_size=val_batch_size,)\n\ntest_batches = datagen1.flow_from_directory(test_path,\n                                            target_size=(image_size,image_size),\n                                            batch_size=32,\n                                            shuffle=False,)\n                                          #subset='validation')","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:30:42.073685Z","iopub.execute_input":"2024-01-14T17:30:42.074011Z","iopub.status.idle":"2024-01-14T17:30:55.624045Z","shell.execute_reply.started":"2024-01-14T17:30:42.073976Z","shell.execute_reply":"2024-01-14T17:30:55.623174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Update this with your actual class names\nclass_names = ['class0', 'class1', 'class2', 'class3', 'class4', 'class5', 'class6']\n\nimages, labels = next(train_batches)\nplt.figure(figsize=(12, 6))\nfor i in range(len(images)):  # This will be the number of images in the batch, which is 4 in your case\n    plt.subplot(1, 4, i+1)\n    plt.imshow(images[i])\n    # Decode the one-hot encoded label to get the class index\n    class_index = np.argmax(labels[i])\n    # Use the class index to get the corresponding class name\n    plt.title(f'Class: {class_names[class_index]}')\nplt.axis('off')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:30:55.625120Z","iopub.execute_input":"2024-01-14T17:30:55.625412Z","iopub.status.idle":"2024-01-14T17:30:56.253581Z","shell.execute_reply.started":"2024-01-14T17:30:55.625387Z","shell.execute_reply":"2024-01-14T17:30:56.252622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#densneet\n%matplotlib inline\nimage, label = next(train_batches)\nplt.figure(figsize=(20,10))\ninline = 4\nfor i in range(inline):\n    #print(image.size())\n    plt.subplot(2, inline, i%inline +1)\n    plt.axis('off')\n    plt.imshow(image[i])\n    plt.title(f'Label: {label}')\n    plt.subplot(2, inline, i%inline +5)\n    plt.axis('off')\n    plt.imshow(image[i].astype(np.uint8))\n\n# import matplotlib.pyplot as plt\n# import numpy as np\n\n# # Assuming you have an array or list of class names corresponding to the indices of the one-hot encoding\n# class_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']  # update this with your actual class names\n\n# %matplotlib inline\n# image, label = next(train_batches)  # Assuming train_batches is an iterator that yields batches of images and one-hot labels\n# plt.figure(figsize=(20,10))\n# inline = 4\n\n# for i in range(inline):\n#     plt.subplot(2, inline, i%inline +1)\n#     plt.axis('off')\n#     plt.imshow(image[i])\n#     # Decode the one-hot encoded label to get the class index\n#     class_index = np.argmax(label[i])\n#     # Use the class index to get the corresponding class name\n#     plt.title(f'Class: {class_names[class_index]}')\n\n#     plt.subplot(2, inline, i%inline +5)\n#     plt.axis('off')\n#     # Assuming image[i] is already in the correct dtype for visualization, if not, cast it appropriately\n#     plt.imshow(image[i].astype(np.uint8))\n\n# plt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:30:56.255253Z","iopub.execute_input":"2024-01-14T17:30:56.255615Z","iopub.status.idle":"2024-01-14T17:30:58.241304Z","shell.execute_reply.started":"2024-01-14T17:30:56.255585Z","shell.execute_reply":"2024-01-14T17:30:58.240274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, labels = next(train_batches)\nprint('Image batch shape:', images.shape)\nprint('Label batch shape:', labels.shape)\nprint('First image label:', labels[0])\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:30:58.246400Z","iopub.execute_input":"2024-01-14T17:30:58.246823Z","iopub.status.idle":"2024-01-14T17:30:58.271790Z","shell.execute_reply.started":"2024-01-14T17:30:58.246787Z","shell.execute_reply":"2024-01-14T17:30:58.270697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"# Setting TPU as main device for training, if you get warnings while working with tpu's ignore them.\n\nDEVICE = 'TPU'\nif DEVICE == 'TPU':\n    print('connecting to TPU...')\n    try:        \n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print('Could not connect to TPU')\n        tpu = None\n\n    if tpu:\n        try:\n            print('Initializing  TPU...')\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print('TPU initialized')\n        except _:\n            print('Failed to initialize TPU!')\n    else:\n        DEVICE = 'GPU'\n\nif DEVICE != 'TPU':\n    print('Using default strategy for CPU and single GPU')\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == 'GPU':\n    print('Num GPUs Available: ',\n          len(tf.config.experimental.list_physical_devices('GPU')))\n\nprint('REPLICAS: ', strategy.num_replicas_in_sync)\nAUTO = tf.data.experimental.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:30:58.273122Z","iopub.execute_input":"2024-01-14T17:30:58.273468Z","iopub.status.idle":"2024-01-14T17:30:58.287353Z","shell.execute_reply.started":"2024-01-14T17:30:58.273441Z","shell.execute_reply":"2024-01-14T17:30:58.286205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = dict(\n           batch_size=4,\n           img_size=384,\n    \n           lr_start=0.000005,\n           lr_max=0.00000125,\n           lr_min=0.000001,\n           lr_rampup=5,\n           lr_sustain=0,\n           lr_decay=0.8,\n           epochs=12,\n    \n           transform_prob=1.0,\n           rot=180.0,\n           shr=2.0,\n           hzoom=8.0,\n           wzoom=8.0,\n           hshift=8.0,\n           wshift=8.0,\n    \n           optimizer='adam',\n           label_smooth_fac=0.05,\n           tta_steps=20\n            \n        )","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:30:58.288782Z","iopub.execute_input":"2024-01-14T17:30:58.289464Z","iopub.status.idle":"2024-01-14T17:30:58.303924Z","shell.execute_reply.started":"2024-01-14T17:30:58.289428Z","shell.execute_reply":"2024-01-14T17:30:58.302926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <a id='the_destination'>Wavelet with residual block</a>\n#### [Return Contents](#intro)","metadata":{"id":"Iy4X8Z-c02Ve"}},{"cell_type":"markdown","source":"# <a id='Xception'>Xception</a>\n#### [Return Contents](#intro)","metadata":{}},{"cell_type":"code","source":"base_model = keras.applications.xception.Xception(weights=\"imagenet\",\n                                                  include_top=False)\navg = keras.layers.GlobalAveragePooling2D()(base_model.output)\noutput = keras.layers.Dense(7, activation=\"softmax\")(avg)\nmodel = keras.models.Model(inputs=base_model.input, outputs=output)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:30:58.305571Z","iopub.execute_input":"2024-01-14T17:30:58.305989Z","iopub.status.idle":"2024-01-14T17:31:01.117402Z","shell.execute_reply.started":"2024-01-14T17:30:58.305948Z","shell.execute_reply":"2024-01-14T17:31:01.116453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index, layer in enumerate(base_model.layers):\n    print(index, layer.name)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:31:01.118493Z","iopub.execute_input":"2024-01-14T17:31:01.118767Z","iopub.status.idle":"2024-01-14T17:31:01.126396Z","shell.execute_reply.started":"2024-01-14T17:31:01.118743Z","shell.execute_reply":"2024-01-14T17:31:01.125401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    \n    ''' This function gets the layers inclunding efficientnet ones. '''\n    \n    model_input = tf.keras.Input(shape=(224,224, 3),\n                                 name='img_input')\n\n    dummy = tf.keras.layers.Lambda(lambda x: x)(model_input)\n\n\n\n    x = keras.applications.xception.Xception(weights=\"imagenet\",\n                                                  include_top=False,\n                                                  input_shape=(224,224, 3),\n                                                  pooling='avg')(dummy)\n    x = tf.keras.layers.Dense(7, activation='softmax')(x)\n    \n    \"\"\"\n    x = efn.EfficientNetB4(include_top=False,\n                           weights='noisy-student',\n                           input_shape=(224,224, 3),\n                           pooling='avg')(dummy)\n    x = tf.keras.layers.Dense(7, activation='softmax')(x)\n    outputs.append(x)\n    \"\"\"\n    \"\"\"\n    x = efn.EfficientNetB5(include_top=False,\n                           weights='noisy-student',\n                           input_shape=(224,224, 3),\n                           pooling='avg')(dummy)\n    x = tf.keras.layers.Dense(7, activation='softmax')(x)\n    outputs.append(x)\n    \"\"\"\n\n    model = tf.keras.Model(model_input, x, name='aNetwork')\n    model.summary()\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:34:52.752294Z","iopub.execute_input":"2024-01-14T17:34:52.752756Z","iopub.status.idle":"2024-01-14T17:34:52.761511Z","shell.execute_reply.started":"2024-01-14T17:34:52.752723Z","shell.execute_reply":"2024-01-14T17:34:52.760299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"efficient = get_model()\nfor index, layer in enumerate(efficient.layers):\n    print(index, layer.name)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:34:56.257509Z","iopub.execute_input":"2024-01-14T17:34:56.258246Z","iopub.status.idle":"2024-01-14T17:34:58.547006Z","shell.execute_reply.started":"2024-01-14T17:34:56.258193Z","shell.execute_reply":"2024-01-14T17:34:58.545916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compileNewModel():\n    \n    ''' Configuring the model with losses and metrics. '''    \n    \n    with strategy.scope():\n        model = efficient\n\n    with strategy.scope():\n        model.compile(optimizer='adam', loss='categorical_crossentropy', \n                      metrics=['accuracy'])\n        #tf.keras.metrics.AUC(name='auc')\n    return model\n\ndef getLearnRateCallback(cfg):\n    \n    ''' Using callbacks for learning rate adjustments. '''\n    \n    lr_start = cfg['lr_start']\n    lr_max = cfg['lr_max'] * strategy.num_replicas_in_sync * cfg['batch_size']\n    lr_min = cfg['lr_min']\n    lr_rampup = cfg['lr_rampup']\n    lr_sustain = cfg['lr_sustain']\n    lr_decay = cfg['lr_decay']\n\n    def lrfn(epoch):\n        if epoch < lr_rampup:\n            lr = (lr_max - lr_start) / lr_rampup * epoch + lr_start\n        elif epoch < lr_rampup + lr_sustain:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_rampup -\n                                                lr_sustain) + lr_min\n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback\n\n\ndef learnModel(model, ds_train, cfg, ds_val):\n    \n    ''' Fitting things together for training '''\n    \n    filepath1 = \"Efficient_att_ens.h5\"\n    checkpoint = ModelCheckpoint(filepath1, monitor='val_accuracy', verbose=1, \n                             save_best_only=True, mode='max', save_weights_only = True)\n    callbacks = [getLearnRateCallback(cfg), checkpoint]\n\n    history = model.fit(ds_train,\n                        validation_data=ds_val,\n                        verbose=True,\n                        epochs=120,\n                        callbacks=callbacks)\n    return history","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:36:14.333465Z","iopub.execute_input":"2024-01-14T17:36:14.333854Z","iopub.status.idle":"2024-01-14T17:36:14.346246Z","shell.execute_reply.started":"2024-01-14T17:36:14.333818Z","shell.execute_reply":"2024-01-14T17:36:14.345153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#efficient net bou7dou i have to save it tooo.. # hada wavelet with global dolg i have to save it (la 2eme fois je dois uploader les meilleurs poids avant enregistremnt)\nmodel1 = compileNewModel()\nhistory1 = learnModel(model1, train_batches, cfg, valid_batches)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T17:35:31.866815Z","iopub.execute_input":"2024-01-14T17:35:31.867447Z","iopub.status.idle":"2024-01-14T17:36:05.474011Z","shell.execute_reply.started":"2024-01-14T17:35:31.867417Z","shell.execute_reply":"2024-01-14T17:36:05.472465Z"},"trusted":true},"execution_count":null,"outputs":[]}]}